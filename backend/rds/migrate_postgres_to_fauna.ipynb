{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import secretmanager\n",
    "\n",
    "from faunadb import query as q\n",
    "from faunadb.objects import Ref\n",
    "from faunadb.client import FaunaClient\n",
    "\n",
    "def get_client():\n",
    "    print('grabbing secret')\n",
    "\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "    secret_name = \"fauna_deepcite_db\"\n",
    "    project_id = \"deepcite-306405\"\n",
    "\n",
    "    request = {\"name\": f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"}\n",
    "    response = client.access_secret_version(request)\n",
    "    secret_string = response.payload.data.decode(\"UTF-8\")\n",
    "\n",
    "    return FaunaClient(secret=secret_string, domain='db.us.fauna.com')\n",
    "\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_colwidth = 100\n",
    "import json\n",
    "\n",
    "def fauna_to_df(fauna):\n",
    "  data = [doc['data'] for doc in fauna['data']]\n",
    "  df = pd.DataFrame.from_records(data)\n",
    "\n",
    "  return df\n",
    "\n",
    "def grab_fauna(collection_name, size = 100000):\n",
    "  return client.query(\n",
    "    q.map_(\n",
    "      lambda x: q.get(x),\n",
    "      q.paginate(q.documents(q.collection(collection_name)), size=size)\n",
    "    )\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 100\n",
    "import json\n",
    "\n",
    "def grab_postgres(table):\n",
    "    with open('database_config.json') as json_file:\n",
    "        db_config = json.load(json_file)['gcp']\n",
    "    conn = psycopg2.connect(host=db_config['host'], user=db_config['user'], password=db_config['password'], database=db_config['database'], port=db_config['port'])\n",
    "    sql = f'SELECT * FROM \"{table}\" ORDER by \"created_at\" DESC;'\n",
    "    call_df_postgres = pd.read_sql_query(sql, conn)\n",
    "    return call_df_postgres\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_data_and_compare(collection, table):\n",
    "    df_postgres = grab_postgres(table).drop_duplicates(subset=['base_id', 'source_id', 'user_id', 'stage', 'redact'])\n",
    "    fauna = grab_fauna(collection)\n",
    "    df_fauna = fauna_to_df(fauna).drop_duplicates(subset=['base_id', 'source_id', 'user_id', 'stage', 'redact'])\n",
    "\n",
    "    df = pd.merge(df_postgres, df_fauna, on=['base_id', 'source_id', 'user_id', 'stage', 'redact'], how='left', indicator='Exist')\n",
    "    df = df[['user_id', 'base_id', 'source_id', 'stage', 'current_versions_x',\n",
    "       'created_at', 'redact', 'Exist']]\n",
    "    df = df.rename(columns={'current_versions_x': 'current_versions'})\n",
    "    # df['Exist'] = np.where(df.Exist == 'both', True, False)\n",
    "\n",
    "    # missing_df_postgres = df_postgres[~df_postgres['id'].isin(df_fauna['id'])]\n",
    "    missing_df_postgres = df[df['Exist'] == 'left_only'].drop(columns=['Exist'])\n",
    "    print(f'length of missing postgres: {len(missing_df_postgres)}')\n",
    "\n",
    "    same_df_postgres = df[df['Exist'] == 'both'].drop(columns=['Exist'])\n",
    "    print(f'length of matching postgres and fauna: {len(same_df_postgres)}')\n",
    "\n",
    "    # call_df_fauna_which_match_postgres = df_fauna[df_fauna['id'].isin(same_df_postgres['id'])] ## Remove the two rows only present in fauna\n",
    "    print(f'''Check if length of postges match fauna: \n",
    "    {len(df_fauna) == len(same_df_postgres)}''')\n",
    "\n",
    "    return same_df_postgres, fauna, missing_df_postgres\n",
    "\n",
    "same_df_postgres, fauna, missing_df_postgres = grab_data_and_compare('deepcite_source', 'source_label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_df_postgres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare missing json data for fauna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct postgres after merge\n",
    "# same_df_postgres_clean = same_df_postgres[['user_id', 'base_id', 'source_id', 'stage', 'current_versions_x',\n",
    "#        'created_at', 'redact']]\n",
    "# same_df_postgres_clean = same_df_postgres_clean.rename(columns={'current_versions_x': 'current_versions'})\n",
    "\n",
    "\n",
    "# Drop duplicate json data\n",
    "fauna_json_clean = []\n",
    "fauna_json = [doc['data'] for doc in fauna['data']]\n",
    "for value in fauna_json:\n",
    "    if not [item for item in fauna_json_clean if check_json_matches(value,item)]:\n",
    "        fauna_json_clean.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordered(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        return sorted((k, ordered(v)) for k, v in obj.items())\n",
    "    if isinstance(obj, list):\n",
    "        return sorted(ordered(x) for x in obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def check_json_matches(a,b):\n",
    "    return ordered(a) == ordered(b)\n",
    "\n",
    "same_json = json.loads(same_df_postgres.to_json(orient='records'))\n",
    "for obj in same_json:\n",
    "    obj.pop('created_at')\n",
    "\n",
    "len(same_json) - len(fauna_json_clean)\n",
    "print(f\"Does the json from postgres match json from fauna: {check_json_matches(same_json, fauna_json_clean)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_missing = json.loads(missing_df_postgres.to_json(orient='records'))\n",
    "with open('missing_deepcite_source.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_missing, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! brew install fauna-shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! fauna import --path=./missing_deepcite_source.json --collection=deepcite_call --append --dry-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d794fdd8b1589b15a1d4ddc86948b0006b97f30cf6c4e08e223d9b7ec035ef8"
  },
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit ('v-env-test': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
